{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EECS189 Project T Final Notebook\n",
    "## project title here :D\n",
    "## This is the solution notebook, so all code will be written out. Specific lines will be left blank for students to fill in\n",
    "    \n",
    "Topic: 9. Training/Testing, Cross-Validation, Bias-Variance\n",
    "\n",
    "By: Team Sean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_fns import *\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Setup\n",
    "[TODO paste the The Setup slide from the slide deck once that's finalized.\n",
    "\n",
    "Something like:\n",
    "\n",
    "YOU have been chosen to pioneer the development of a machine learning system that ranks startups for probability of success.  We give you profiles of previous startups, including their capital, resource costs, country, Public or Nonprofit status, the amount of success they achieved years later, and much more. Can you estimate the success rates for todayâ€™s slew of new (fictional) startups? The investment firms are waiting to hear about the insight you provide!\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing the Training Data\n",
    "\n",
    "The first thing to do is always to find out what you're working with. We load the data X and labels y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO load X and y\n",
    "\n",
    "# shuffle x and y?\n",
    "\n",
    "# Features present in the data in order. These column names will help you interpret trends you see in the data\n",
    "# This was originally nested alongside the numerical data, but OLS requires us to use a matrix instead of a dictionary\n",
    "# TODO populate this with the actual column names\n",
    "FEATURES = ['product name', 'price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO something like \"plot some of the features of startups with respect to their success rates. What do you notice about the correlations? Are there correlations?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_feat_selector(features):\n",
    "    \"\"\"\n",
    "    Helper function to create a subset of the data that will only include certain features\n",
    "    A full list of features is defined in FEATURES\n",
    "    \"\"\"\n",
    "    for f in features:\n",
    "        assert f in FEATURES, \"'{}' is not defined in the varaible FEATURES!\".format(f)\n",
    "    def feat_selector(X):\n",
    "        indices = [FEATURES.index(f) for f in features]\n",
    "        return X[:, indices]\n",
    "    return feat_selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structuring Your Machine Learning Model\n",
    "\n",
    "In this project, we will focus on the general process behind training many machine learning models. Thus, we will use one that will give us quick training results: Ordinary Least Squares (OLS).\n",
    "\n",
    "---\n",
    "To the mathematically inclined, OLS is an algorithm that solves the following optimization problem on the training data and hopefully gives us weights that will help us predict labels for test data:\n",
    "\n",
    "$$\\min_{w} ||y-Xw||^2$$\n",
    "\n",
    "To find the weights of our machine learning model $w$, we use the below least squares solution as a \"training step\":\n",
    "\n",
    "$$w = (X^T X)^{-1} X^T y$$\n",
    "\n",
    "---\n",
    "\n",
    "Though coding OLS is not bad, let's get used to the sklearn library! \n",
    "\n",
    "Use **LinearRegression** from [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) to implement the training step below. You may find the examples in the documentation very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X_train, y_train):\n",
    "    \"\"\"\n",
    "    X_train - Training data\n",
    "    y_train - Training labels\n",
    "    Return reg, an instance of LinearRegression.fit() that represents the trained model\n",
    "    \"\"\"\n",
    "    ##### START #####\n",
    "    reg = LinearRegression().fit(X_train, y_train)\n",
    "    ##### END #####\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO something about changing up the features passed in X_train based on the visualizations above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring the Bias and Variance of Your Model\n",
    "\n",
    "Is the model doing well?\n",
    "\n",
    "As noted in lecture, bias is generally expressed as a model's tendency to approximate certain functions even if conflicting features are in the training set, and variance is generally expressed as a model's difference in performance on the test set given a different training set. Also remember the irreducible error is that which cannot be eliminated because it is in our inherently noisy measurements of the labels.\n",
    "\n",
    "A mathematical formulation is below:\n",
    "\n",
    "$$\\text{Total Noise} = (E[h(x|D)] - f(x))^2 + Var(h(x|D)) + Var(Z)$$\n",
    "\n",
    "where h(x|D) is the model's prediction given a training dataset, f(x) is the true label, and Z is the inherent noise in the labels. These terms are bias, variance, and irreducible error, respectively. A detailed derivation can be found [here](https://www.eecs189.org/static/notes/n5.pdf) or in the notes.\n",
    "\n",
    "## The Game Plan\n",
    "\n",
    "1. Since these values are evaluated over many different training datasets, let's structure this like k-fold cross validation so we can randomly sample datasets. Perhaps, you can use [sklearn.model_selection.KFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html). **NOTE:** X_test must be the same for all datasets for the bias variance measurement corresponding to the above to be correct.\n",
    "\n",
    "2. For each of the k splits, \n",
    " - train your model using your selected features\n",
    " - record predictions for each test datapoint x\n",
    "\n",
    "3. After gathering the above information, average the predicted label over the k splits for each input x to obtain E[h(x|D)] and combine with the appropriate y label f(x). Average these values over inputs x to get the bias\n",
    "\n",
    "4. Compute the variance of predictions for each input x. Then average over inputs x to get the variance Var(h(x|D))\n",
    "\n",
    "What is the bias of your model? The variance? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO this  function is COMPLETELY untested\n",
    "\n",
    "def get_bias_variance(X, y, feat_selector):\n",
    "    \"\"\"\n",
    "    X- the original training data\n",
    "    y- the labels for the original training data\n",
    "    feat_selector- a function created by create_function_selector()\n",
    "    \"\"\"\n",
    "    \n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    ##### START STEP 1 #####\n",
    "    n_rest = int(X.shape[0] * 0.75)\n",
    "    X_rest, X_test = X[:n_rest], X[n_rest:]\n",
    "    y_rest, y_test = y[:n_rest], y[n_rest:]\n",
    "    \n",
    "    kf = sklearn.model_selection.KFold(n_splits=4)\n",
    "    for train_index, test_index in kf.split(X_rest):\n",
    "        X_train, y_train = X[train_index], y[train_index]\n",
    "    ##### END STEP 1 #####\n",
    "        ##### START STEP 2 #####\n",
    "        reg = train(X_train, y_train)\n",
    "        predictions.append(reg.predict(X_test))\n",
    "        true_labels.append(y_test)\n",
    "        ##### END STEP 2 #####\n",
    "    \n",
    "    ##### START STEP 3 #####\n",
    "    bias = np.mean((np.mean(predictions, axis=0) - true_labels[0])**2)\n",
    "    ##### END STEP 3 #####\n",
    "    \n",
    "    ##### START STEP 4 #####\n",
    "    variance = np.std(np.mean(predictions, axis=0))\n",
    "    ##### END STEP 4 #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation\n",
    "\n",
    "TODO do real k-fold cross validation to compare different sets of features\n",
    "\n",
    "TODO say WOW the featurizations that have low training error and high test error are exactly the ones that have low variance, that was calculated in the previous part! O:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO something about repeating the above until your model prediction accuracy is ~90% (base this percentage on the best staff solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
